{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Model Quality Monitor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Setup <a id='setup'></a>\n",
    "\n",
    "In this section, you will import the necessary libraries, setup variables and examine data that was used to train the XGBoost customer churn model provided with this notebook.\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "* The AWS region used to host your model.\n",
    "* The IAM role associated with this SageMaker notebook instance.\n",
    "* The S3 bucket used to store the data used to train your model, any additional model data, and the data captured from model invocations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "CPU times: user 1.49 s, sys: 188 ms, total: 1.68 s\n",
      "Wall time: 2.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import boto3\n",
    "from time import sleep\n",
    "from threading import Thread\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sagemaker import get_execution_role, session, Session, image_uris\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.processing import ProcessingJob\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "session = Session()\n",
    "sagemaker_runtime_client = session.sagemaker_runtime_client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 AWS region and  IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleArn: arn:aws:iam::904981812149:role/LabRole\n",
      "Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Get Execution role\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn:\", role)\n",
    "\n",
    "region = session.boto_region_name\n",
    "print(\"Region:\", region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 S3 bucket and prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo Bucket: sagemaker-us-east-1-904981812149\n",
      "Image URI: 156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-analyzer\n",
      "Capture path: s3://sagemaker-us-east-1-904981812149/sagemaker/Churn-ModelQualityMonitor-20201201/datacapture\n",
      "Ground truth path: s3://sagemaker-us-east-1-904981812149/sagemaker/Churn-ModelQualityMonitor-20201201/ground_truth_data/2024-06-11-02-19-48\n",
      "Report path: s3://sagemaker-us-east-1-904981812149/sagemaker/Churn-ModelQualityMonitor-20201201/reports\n"
     ]
    }
   ],
   "source": [
    "# Setup S3 bucket\n",
    "# You can use a different bucket, but make sure the role you chose for this notebook\n",
    "# has the s3:PutObject permissions. This is the bucket into which the data is captured\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "\n",
    "print(\"Demo Bucket:\", bucket)\n",
    "prefix = \"sagemaker/Churn-ModelQualityMonitor-20201201\"\n",
    "\n",
    "##S3 prefixes\n",
    "data_capture_prefix = f\"{prefix}/datacapture\"\n",
    "s3_capture_upload_path = f\"s3://{bucket}/{data_capture_prefix}\"\n",
    "\n",
    "ground_truth_upload_path = (\n",
    "    f\"s3://{bucket}/{prefix}/ground_truth_data/{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    ")\n",
    "\n",
    "reports_prefix = f\"{prefix}/reports\"\n",
    "s3_report_path = f\"s3://{bucket}/{reports_prefix}\"\n",
    "\n",
    "##Get the model monitor image\n",
    "monitor_image_uri = image_uris.retrieve(framework=\"model-monitor\", region=region)\n",
    "\n",
    "print(\"Image URI:\", monitor_image_uri)\n",
    "print(f\"Capture path: {s3_capture_upload_path}\")\n",
    "print(f\"Ground truth path: {ground_truth_upload_path}\")\n",
    "print(f\"Report path: {s3_report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this section, you will upload the pretrained model to the S3 bucket, create an Amazon SageMaker Model, create an Amazon SageMaker real time endpoint, and enable data capture on the endpoint to capture endpoint invocations, predictions, and metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This code uploads a pre-trained XGBoost model that is ready for you to deploy. This model was trained using the XGB Churn Prediction Notebook in SageMaker. You can also use your own pre-trained model in this step. If you already have a pretrained model in Amazon S3, you can add it instead by specifying the s3_key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Key: s3://sagemaker-us-east-1-904981812149/sagemaker/Churn-ModelQualityMonitor-20201201\n",
      "Capture path: s3://sagemaker-us-east-1-904981812149/sagemaker/Churn-ModelQualityMonitor-20201201/datacapture\n",
      "Ground truth path: s3://sagemaker-us-east-1-904981812149/sagemaker/Churn-ModelQualityMonitor-20201201/ground_truth_data/2024-06-11-02-19-48\n",
      "Report path: s3://sagemaker-us-east-1-904981812149/sagemaker/Churn-ModelQualityMonitor-20201201/reports\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-904981812149/sagemaker/Churn-ModelQualityMonitor-20201201/xgb-churn-prediction-model.tar.gz'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Upload the pretrained model to S3\n",
    "s3_key = f\"s3://{bucket}/{prefix}\"\n",
    "print(f\"S3 Key: {s3_key}\")\n",
    "\n",
    "s3_capture_upload_path = f\"{s3_key}/datacapture\"\n",
    "ground_truth_upload_path = f\"{s3_key}/ground_truth_data/{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "s3_report_path = f\"{s3_key}/reports\"\n",
    "\n",
    "print(f\"Capture path: {s3_capture_upload_path}\")\n",
    "print(f\"Ground truth path: {ground_truth_upload_path}\")\n",
    "print(f\"Report path: {s3_report_path}\")\n",
    "\n",
    "model_file = \"model/xgb-churn-prediction-model.tar.gz\"\n",
    "\n",
    "model_url = S3Uploader.upload(model_file, s3_key)\n",
    "model_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! You are all set to proceed.\n"
     ]
    }
   ],
   "source": [
    "# Upload some test files\n",
    "S3Uploader.upload(\"test_data/upload-test-file.txt\", f\"s3://{bucket}/test_upload\")\n",
    "print(\"Success! You are all set to proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Churn', 'Account Length', 'VMail Message', 'Day Mins', 'Day Calls', 'Eve Mins', 'Eve Calls', 'Night Mins', 'Night Calls', 'Intl Mins', 'Intl Calls', 'CustServ Calls', 'State_AK', 'State_AL', 'State_AR', 'State_AZ', 'State_CA', 'State_CO', 'State_CT', 'State_DC', 'State_DE', 'State_FL', 'State_GA', 'State_HI', 'State_IA', 'State_ID', 'State_IL', 'State_IN', 'State_KS', 'State_KY', 'State_LA', 'State_MA', 'State_MD', 'State_ME', 'State_MI', 'State_MN', 'State_MO', 'State_MS', 'State_MT', 'State_NC', 'State_ND', 'State_NE', 'State_NH', 'State_NJ', 'State_NM', 'State_NV', 'State_NY', 'State_OH', 'State_OK', 'State_OR', 'State_PA', 'State_RI', 'State_SC', 'State_SD', 'State_TN', 'State_TX', 'State_UT', 'State_VA', 'State_VT', 'State_WA', 'State_WI', 'State_WV', 'State_WY', 'Area Code_408', 'Area Code_415', 'Area Code_510', \"Int'l Plan_no\", \"Int'l Plan_yes\", 'VMail Plan_no', 'VMail Plan_yes']\n",
      "Churn\n"
     ]
    }
   ],
   "source": [
    "test_file = \"test_data/upload-test-file.txt\"\n",
    "test_dataset = \"test_data/test-dataset-input-cols.csv\"\n",
    "validation_dataset = \"test_data/churn-data-with-header.csv\"\n",
    "dataset_type = \"text/csv\"\n",
    "\n",
    "\n",
    "with open(validation_dataset) as f:\n",
    "    headers_line = f.readline().rstrip()\n",
    "all_headers = headers_line.split(\",\")\n",
    "label_header = all_headers[0]\n",
    "print(all_headers)\n",
    "print(label_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This step creates an Amazon SageMaker model from the  model file uploaded to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:  DEMO-xgb-churn-pred-model-monitor-2024-06-11-0219\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"DEMO-xgb-churn-pred-model-monitor-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "print(\"Model name: \", model_name)\n",
    "\n",
    "\n",
    "image_uri = image_uris.retrieve(framework=\"xgboost\", version=\"0.90-1\", region=region)\n",
    "\n",
    "model = Model(role = role, \n",
    "              name =model_name, \n",
    "              image_uri=image_uri, \n",
    "              model_data=model_url, \n",
    "              sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Deploy the model with data capture enabled.\n",
    "Next, deploy the SageMaker model on a specific instance with data capture enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndpointName = DEMO-xgb-churn-model-quality-monitor-2024-06-11-0219\n",
      "------!Deploying model DEMO-xgb-churn-pred-model-monitor-2024-06-11-0219 to endpoint DEMO-xgb-churn-model-quality-monitor-2024-06-11-0219\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = f\"DEMO-xgb-churn-model-quality-monitor-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "print(\"EndpointName =\", endpoint_name)\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True, sampling_percentage=100, destination_s3_uri=s3_capture_upload_path\n",
    ")\n",
    "\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    data_capture_config=data_capture_config,\n",
    ")\n",
    "\n",
    "print(f\"Deploying model {model_name} to endpoint {endpoint_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Create the SageMaker Predictor object from the endpoint to be used for invoking the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name, sagemaker_session=session, serializer=CSVSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending test traffic to the endpoint DEMO-xgb-churn-model-quality-monitor-2024-06-11-0219. \n",
      "Please wait........................................................................................................................\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(f\"Sending test traffic to the endpoint {endpoint_name}. \\nPlease wait\", end=\"\")\n",
    "test_dataset_size = 0  # record the number of rows in data we're sending for inference\n",
    "with open(test_dataset, \"r\") as f:\n",
    "    for row in f:\n",
    "        if test_dataset_size < 120:\n",
    "            payload = row.rstrip(\"\\n\")\n",
    "            response = sagemaker_runtime_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                Body=payload,\n",
    "                ContentType=dataset_type,\n",
    "            )\n",
    "            prediction = response[\"Body\"].read()\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            time.sleep(0.5)\n",
    "        test_dataset_size += 1\n",
    "\n",
    "print()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Captured Data\n",
    "\n",
    "\n",
    "Now list the data capture files stored in Amazon S3. You should expect to see different files from different time periods organized based on the hour in which the invocation occurred. The format of the Amazon S3 path is:\n",
    "\n",
    "`s3://{destination-bucket-prefix}/{endpoint-name}/{variant-name}/yyyy/mm/dd/hh/filename.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for captures to show up........................................................................................................................\n",
      "Found Capture Files:\n",
      "s3://sagemaker-us-east-1-904981812149/sagemaker/Churn-ModelQualityMonitor-20201201/datacapture/DEMO-xgb-churn-model-quality-monitor-2024-06-11-0219/AllTraffic/2024/06/11/02/23-22-548-1c69ec0e-de6c-442d-bb89-d0d3d850f806.jsonl\n",
      " s3://sagemaker-us-east-1-904981812149/sagemaker/Churn-ModelQualityMonitor-20201201/datacapture/DEMO-xgb-churn-model-quality-monitor-2024-06-11-0219/AllTraffic/2024/06/11/02/24-22-614-0d19c6ea-19e7-4433-8306-ddd32f29f9fe.jsonl\n"
     ]
    }
   ],
   "source": [
    "print(\"Waiting for captures to show up\", end=\"\")\n",
    "for _ in range(120):\n",
    "    capture_files = sorted(S3Downloader.list(f\"{s3_capture_upload_path}/{endpoint_name}\"))\n",
    "    if capture_files:\n",
    "        capture_file = S3Downloader.read_file(capture_files[-1]).split(\"\\n\")\n",
    "        capture_record = json.loads(capture_file[0])\n",
    "        if \"inferenceId\" in capture_record[\"eventMetadata\"]:\n",
    "            break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    sleep(1)\n",
    "print()\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files[-3:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "Next, view the contents of a single capture file. Here you should see all the data captured in an Amazon SageMaker specific JSON-line formatted file. Take a quick peek at the first few lines in the captured file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"138,0,46.5,104,186.0,114,167.5,95,9.6,4,4,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"0.9562002420425415\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"2c9c9d3e-864d-442c-b623-06a41c31098c\",\"inferenceTime\":\"2024-06-11T02:24:23Z\"},\"eventVersion\":\"0\"}\n",
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"93,0,176.1,103,199.7,130,263.9,96,8.5,6,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"0.007474285550415516\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"bfcfb2a2-c1ae-4193-a272-e9dfff989b93\",\"inferenceTime\":\"2024-06-11T02:24:24Z\"},\"eventVersion\":\"0\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(capture_file[-3:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the contents of a single line is present below in a formatted JSON file so that you can observe a little better.\n",
    "\n",
    "Again, notice the `inferenceId` attribute that is set as part of the invoke_endpoint call.  If this is present, it will be used to join with ground truth data (otherwise `eventId` will be used):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"captureData\": {\n",
      "    \"endpointInput\": {\n",
      "      \"observedContentType\": \"text/csv\",\n",
      "      \"mode\": \"INPUT\",\n",
      "      \"data\": \"23,31,156.6,84,161.5,96,294.6,107,9.4,6,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0,1\",\n",
      "      \"encoding\": \"CSV\"\n",
      "    },\n",
      "    \"endpointOutput\": {\n",
      "      \"observedContentType\": \"text/csv; charset=utf-8\",\n",
      "      \"mode\": \"OUTPUT\",\n",
      "      \"data\": \"0.02614814229309559\",\n",
      "      \"encoding\": \"CSV\"\n",
      "    }\n",
      "  },\n",
      "  \"eventMetadata\": {\n",
      "    \"eventId\": \"337171e6-ba47-4143-94f7-3ee87610f99a\",\n",
      "    \"inferenceTime\": \"2024-06-11T02:24:22Z\"\n",
      "  },\n",
      "  \"eventVersion\": \"0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(capture_record, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate prediction data for Model bias  Monitoring\n",
    "\n",
    "Start generating some artificial traffic.  The cell below starts a thread to send some traffic to the endpoint. Note that you need to stop the kernel to terminate this thread. If there is no traffic, the monitoring jobs are marked as `Failed` since there is no data to process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the new attribute `inferenceId`, which we're setting when invoking the endpoint. This is used to join the prediction data with the ground truth data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_endpoint(ep_name, file_name):\n",
    "    with open(file_name, \"r\") as f:\n",
    "        i = 0\n",
    "        for row in f:\n",
    "            payload = row.rstrip(\"\\n\")\n",
    "            response = session.sagemaker_runtime_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                ContentType=\"text/csv\",\n",
    "                Body=payload,\n",
    "                InferenceId=str(i),  # unique ID per row\n",
    "            )[\"Body\"].read()\n",
    "            i += 1\n",
    "            sleep(1)\n",
    "\n",
    "\n",
    "def invoke_endpoint_forever():\n",
    "    while True:\n",
    "        try:\n",
    "            invoke_endpoint(endpoint_name, \"test_data/test-dataset-input-cols.csv\")\n",
    "        except session.sagemaker_runtime_client.exceptions.ValidationError:\n",
    "            pass\n",
    "\n",
    "\n",
    "thread = Thread(target=invoke_endpoint_forever)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate synthetic ground truth\n",
    "\n",
    "Next, start generating ground truth data. The model quality job will fail if there's no ground truth data to merge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def ground_truth_with_id(inference_id):\n",
    "    random.seed(inference_id)  # to get consistent results\n",
    "    rand = random.random()\n",
    "    return {\n",
    "        \"groundTruthData\": {\n",
    "            \"data\": \"1\" if rand < 0.7 else \"0\",  # randomly generate positive labels 70% of the time\n",
    "            \"encoding\": \"CSV\",\n",
    "        },\n",
    "        \"eventMetadata\": {\n",
    "            \"eventId\": str(inference_id),\n",
    "        },\n",
    "        \"eventVersion\": \"0\",\n",
    "    }\n",
    "\n",
    "\n",
    "def upload_ground_truth(records, upload_time):\n",
    "    fake_records = [json.dumps(r) for r in records]\n",
    "    data_to_upload = \"\\n\".join(fake_records)\n",
    "    target_s3_uri = f\"{ground_truth_upload_path}/{upload_time:%Y/%m/%d/%H/%M%S}.jsonl\"\n",
    "    print(f\"Uploading {len(fake_records)} records to\", target_s3_uri)\n",
    "    S3Uploader.upload_string_as_file_body(data_to_upload, target_s3_uri)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 334 records to s3://sagemaker-us-east-1-904981812149/sagemaker/Churn-ModelQualityMonitor-20201201/ground_truth_data/2024-06-11-02-19-48/2024/06/11/02/2818.jsonl\n"
     ]
    }
   ],
   "source": [
    "NUM_GROUND_TRUTH_RECORDS = 334  # 334 are the number of rows in data we're sending for inference\n",
    "\n",
    "\n",
    "def generate_fake_ground_truth_forever():\n",
    "    j = 0\n",
    "    while True:\n",
    "        fake_records = [ground_truth_with_id(i) for i in range(NUM_GROUND_TRUTH_RECORDS)]\n",
    "        upload_ground_truth(fake_records, datetime.utcnow())\n",
    "        j = (j + 1) % 5\n",
    "        sleep(60 * 60)  # do this once an hour\n",
    "\n",
    "\n",
    "gt_thread = Thread(target=generate_fake_ground_truth_forever)\n",
    "gt_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Upload the predictions as a baseline dataset.\n",
    "Now we will upload the predictions made using validation dataset to S3 which will be used for creating model quality baseline statistics and constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline data uri: s3://sagemaker-us-east-1-904981812149/sagemaker/Churn-ModelQualityMonitor-20201201/baselining/data\n",
      "Baseline results uri: s3://sagemaker-us-east-1-904981812149/sagemaker/Churn-ModelQualityMonitor-20201201/baselining/results\n"
     ]
    }
   ],
   "source": [
    "baseline_prefix = prefix + \"/baselining\"\n",
    "baseline_data_prefix = baseline_prefix + \"/data\"\n",
    "baseline_results_prefix = baseline_prefix + \"/results\"\n",
    "\n",
    "baseline_data_uri = f\"s3://{bucket}/{baseline_data_prefix}\"\n",
    "baseline_results_uri = f\"s3://{bucket}/{baseline_results_prefix}\"\n",
    "print(f\"Baseline data uri: {baseline_data_uri}\")\n",
    "print(f\"Baseline results uri: {baseline_results_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Bias Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model bias monitor can detect bias drift of Machine Learning models in a regular basis. Similar to the other monitoring types, the standard procedure of creating a model bias monitor is first baselining and then monitoring schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import ModelBiasMonitor\n",
    "\n",
    "model_bias_monitor = ModelBiasMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=session,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of dataset files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataConfig stores information about the dataset to be analyzed, for example the dataset file, its format (CSV or JSONLines), headers (if any) and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline results uri: s3://sagemaker-us-east-1-904981812149/sagemaker/Churn-ModelQualityMonitor-20201201/baselining/results\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.clarify import DataConfig\n",
    "\n",
    "print(f\"Baseline results uri: {baseline_results_uri}\")\n",
    "\n",
    "\n",
    "model_bias_baselining_job_result_uri = f\"{baseline_results_uri}/model_bias\"\n",
    "\n",
    "model_bias_data_config = DataConfig(\n",
    "    s3_data_input_path=validation_dataset,\n",
    "    s3_output_path=model_bias_baselining_job_result_uri,\n",
    "    label=label_header,\n",
    "    headers=all_headers,\n",
    "    dataset_type=dataset_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BiasConfig is the configuration of the sensitive groups in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.clarify import BiasConfig\n",
    "\n",
    "model_bias_config = BiasConfig(\n",
    "    label_values_or_threshold=[1],\n",
    "    facet_name=\"Account Length\",\n",
    "    facet_values_or_threshold=[100],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ModelPredictedLabelConfig specifies how to extract a predicted label from the model output. This model returns probability that user will churn. Here choose an arbitrary 0.8 cutoff to consider that a customer will churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.clarify import ModelPredictedLabelConfig\n",
    "\n",
    " \n",
    "model_predicted_label_config = ModelPredictedLabelConfig(\n",
    "    probability_threshold=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ModelConfig is configuration related to model to be used for inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.clarify import ModelConfig\n",
    "\n",
    "model_name = f\"DEMO-xgb-churn-pred-model-monitor-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model_name=model_name,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    content_type=dataset_type,\n",
    "    accept_type=dataset_type,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kick off baselining job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name baseline-suggestion-job-2024-06-11-02-28-19-816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelBiasMonitor baselining job: baseline-suggestion-job-2024-06-11-02-28-19-816\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_bias_monitor.suggest_baseline(\n",
    "    model_config=model_config,\n",
    "    data_config=model_bias_data_config,\n",
    "    bias_config=model_bias_config,\n",
    "    model_predicted_label_config=model_predicted_label_config,\n",
    ")\n",
    "print(f\"ModelBiasMonitor baselining job: {model_bias_monitor.latest_baselining_job_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Processing job baseline-suggestion-job-2024-06-11-02-28-19-816: Failed. Reason: ClientError: An error occurred (ValidationException) when calling the CreateEndpointConfig operation: Could not find model \"DEMO-xgb-churn-pred-model-monitor-2024-06-11-0228\"., exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_bias_monitor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_baselining_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model_bias_constraints \u001b[38;5;241m=\u001b[39m model_bias_monitor\u001b[38;5;241m.\u001b[39msuggested_constraints()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/processing.py:1115\u001b[0m, in \u001b[0;36mProcessingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mlogs_for_processing_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_processing_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:5126\u001b[0m, in \u001b[0;36mSession.wait_for_processing_job\u001b[0;34m(self, job, poll)\u001b[0m\n\u001b[1;32m   5112\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for an Amazon SageMaker Processing job to complete.\u001b[39;00m\n\u001b[1;32m   5113\u001b[0m \n\u001b[1;32m   5114\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5123\u001b[0m \u001b[38;5;124;03m    exceptions.UnexpectedStatusException: If the processing job fails.\u001b[39;00m\n\u001b[1;32m   5124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5125\u001b[0m desc \u001b[38;5;241m=\u001b[39m _wait_until(\u001b[38;5;28;01mlambda\u001b[39;00m: _processing_job_status(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client, job), poll)\n\u001b[0;32m-> 5126\u001b[0m \u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessingJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m desc\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:8042\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   8036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   8037\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   8038\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8039\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8040\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8041\u001b[0m     )\n\u001b[0;32m-> 8042\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   8043\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8044\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8045\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8046\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Processing job baseline-suggestion-job-2024-06-11-02-28-19-816: Failed. Reason: ClientError: An error occurred (ValidationException) when calling the CreateEndpointConfig operation: Could not find model \"DEMO-xgb-churn-pred-model-monitor-2024-06-11-0228\"., exit code: 1"
     ]
    }
   ],
   "source": [
    "\n",
    "model_bias_monitor.latest_baselining_job.wait(logs=False)\n",
    "model_bias_constraints = model_bias_monitor.suggested_constraints()\n",
    "print()\n",
    "print(f\"ModelBiasMonitor suggested constraints: {model_bias_constraints.file_s3_uri}\")\n",
    "print(S3Downloader.read_file(model_bias_constraints.file_s3_uri))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule Model Bias Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.model_monitor.clarify_model_monitoring:Uploading analysis config to {s3_uri}.\n",
      "INFO:sagemaker.model_monitor.model_monitoring:Creating Monitoring Schedule with name: monitoring-schedule-2024-06-11-02-33-48-308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model bias monitoring schedule: monitoring-schedule-2024-06-11-02-33-48-308\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import BiasAnalysisConfig, CronExpressionGenerator\n",
    "from sagemaker.model_monitor import EndpointInput\n",
    "\n",
    "\n",
    "model_bias_analysis_config = None\n",
    "if not model_bias_monitor.latest_baselining_job:\n",
    "    model_bias_analysis_config = BiasAnalysisConfig(\n",
    "        model_bias_config,\n",
    "        headers=all_headers,\n",
    "        label=label_header,\n",
    "    )\n",
    "\n",
    "schedule_expression = CronExpressionGenerator.hourly()\n",
    " \n",
    "# Create an endpointInput\n",
    "endpointInput = EndpointInput(\n",
    "    endpoint_name=predictor.endpoint_name,\n",
    "    probability_attribute=\"0\",\n",
    "    probability_threshold_attribute=0.5,\n",
    "    destination=\"/opt/ml/processing/input_data\",\n",
    ")\n",
    "    \n",
    "model_bias_monitor.create_monitoring_schedule(\n",
    "    analysis_config=model_bias_analysis_config,\n",
    "    output_s3_uri=s3_report_path,\n",
    "    endpoint_input=endpointInput,\n",
    "    ground_truth_input=ground_truth_upload_path,\n",
    "    schedule_cron_expression=schedule_expression,\n",
    ")\n",
    "print(f\"Model bias monitoring schedule: {model_bias_monitor.monitoring_schedule_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MonitoringScheduleArn': 'arn:aws:sagemaker:us-east-1:904981812149:monitoring-schedule/monitoring-schedule-2024-06-11-02-33-48-308',\n",
       " 'MonitoringScheduleName': 'monitoring-schedule-2024-06-11-02-33-48-308',\n",
       " 'MonitoringScheduleStatus': 'Pending',\n",
       " 'MonitoringType': 'ModelBias',\n",
       " 'CreationTime': datetime.datetime(2024, 6, 11, 2, 33, 49, 152000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2024, 6, 11, 2, 33, 51, 992000, tzinfo=tzlocal()),\n",
       " 'MonitoringScheduleConfig': {'ScheduleConfig': {'ScheduleExpression': 'cron(0 * ? * * *)'},\n",
       "  'MonitoringJobDefinitionName': 'model-bias-job-definition-2024-06-11-02-33-48-308',\n",
       "  'MonitoringType': 'ModelBias'},\n",
       " 'EndpointName': 'DEMO-xgb-churn-model-quality-monitor-2024-06-11-0219',\n",
       " 'ResponseMetadata': {'RequestId': '082bdce3-52a0-440d-9d16-6b9513f2ce96',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '082bdce3-52a0-440d-9d16-6b9513f2ce96',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '607',\n",
       "   'date': 'Tue, 11 Jun 2024 02:33:52 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describing the schedule\n",
    "model_bias_monitor.describe_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.model_monitor.model_monitoring:No executions found for schedule. monitoring_schedule_name: monitoring-schedule-2024-06-11-02-33-48-308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine modelschedule execution\n",
    "bias_executions = model_bias_monitor.list_executions()\n",
    "bias_executions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waiting for the first execution of the Bias Monitor schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A hourly schedule was created above and it will kick off executions ON the hour (plus 0 - 20 min buffer).\n",
      "Waiting for the first execution to happen.............................................."
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "def wait_for_execution_to_start(model_monitor):\n",
    "    print(\n",
    "        \"A hourly schedule was created above and it will kick off executions ON the hour (plus 0 - 20 min buffer).\"\n",
    "    )\n",
    "\n",
    "    print(\"Waiting for the first execution to happen\", end=\"\")\n",
    "    schedule_desc = model_monitor.describe_schedule()\n",
    "    while \"LastMonitoringExecutionSummary\" not in schedule_desc:\n",
    "        schedule_desc = model_monitor.describe_schedule()\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(60)\n",
    "    print()\n",
    "    print(\"Done! Execution has been created\")\n",
    "\n",
    "    print(\"Now waiting for execution to start\", end=\"\")\n",
    "    while schedule_desc[\"LastMonitoringExecutionSummary\"][\"MonitoringExecutionStatus\"] in \"Pending\":\n",
    "        schedule_desc = model_monitor.describe_schedule()\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(10)\n",
    "\n",
    "    print()\n",
    "    print(\"Done! Execution has started\")\n",
    "    \n",
    "\n",
    "wait_for_execution_to_start(model_bias_monitor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for the execution to finish\n",
    "\n",
    "In the previous cell, the first execution has started. This section waits for the execution to finish so that its analysis results are available. Here are the possible terminal states and what each of them mean:\n",
    "\n",
    "Completed - This means the monitoring execution completed and no issues were found in the violations report.\n",
    "\n",
    "CompletedWithViolations - This means the execution completed, but constraint violations were detected.\n",
    "\n",
    "Failed - The monitoring execution failed, maybe due to client error (perhaps incorrect role permissions) or infrastructure issues. Further examination of FailureReason and ExitMessage is necessary to identify what exactly happened.\n",
    "\n",
    "Stopped - job exceeded max runtime or was manually stopped.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Waits for the schedule to have last execution in a terminal status.\n",
    "def wait_for_execution_to_finish(model_monitor):\n",
    "    schedule_desc = model_monitor.describe_schedule()\n",
    "    execution_summary = schedule_desc.get(\"LastMonitoringExecutionSummary\")\n",
    "    if execution_summary is not None:\n",
    "        print(\"Waiting for execution to finish\", end=\"\")\n",
    "        while execution_summary[\"MonitoringExecutionStatus\"] not in [\n",
    "            \"Completed\",\n",
    "            \"CompletedWithViolations\",\n",
    "            \"Failed\",\n",
    "            \"Stopped\",\n",
    "        ]:\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            time.sleep(60)\n",
    "            schedule_desc = model_monitor.describe_schedule()\n",
    "            execution_summary = schedule_desc[\"LastMonitoringExecutionSummary\"]\n",
    "        print()\n",
    "        print(\"Done! Execution has finished\")\n",
    "    else:\n",
    "        print(\"Last execution not found\")\n",
    "\n",
    "        \n",
    "wait_for_execution_to_finish(model_bias_monitor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect execution results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schedule_desc = model_bias_monitor.describe_schedule()\n",
    "execution_summary = schedule_desc.get(\"LastMonitoringExecutionSummary\")\n",
    "if execution_summary and execution_summary[\"MonitoringExecutionStatus\"] in [\n",
    "    \"Completed\",\n",
    "    \"CompletedWithViolations\",\n",
    "]:\n",
    "    last_model_bias_monitor_execution = model_bias_monitor.list_executions()[-1]\n",
    "    last_model_bias_monitor_execution_report_uri = (\n",
    "        last_model_bias_monitor_execution.output.destination\n",
    "    )\n",
    "    print(f\"Report URI: {last_model_bias_monitor_execution_report_uri}\")\n",
    "    last_model_bias_monitor_execution_report_files = sorted(\n",
    "        S3Downloader.list(last_model_bias_monitor_execution_report_uri)\n",
    "    )\n",
    "    print(\"Found Report Files:\")\n",
    "    print(\"\\n \".join(last_model_bias_monitor_execution_report_files))\n",
    "else:\n",
    "    last_model_bias_monitor_execution = None\n",
    "    print(\n",
    "        \"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are violations compared to the baseline, they will be listed here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if last_model_bias_monitor_execution:\n",
    "    model_bias_violations = last_model_bias_monitor_execution.constraint_violations()\n",
    "    if model_bias_violations:\n",
    "        #print(model_bias_violations.body_dict)\n",
    "        bias_violations = model_bias_violations.body_dict[\"violations\"]\n",
    "        bias_violations_df = pd.json_normalize(bias_violations)\n",
    "        bias_violations_df.head(10)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5 - Analyze model quality CloudWatch metrics <a id='analyze-cloudwatch-metrics'></a> \n",
    "\n",
    "In addition to the violations, the monitoring schedule also emits CloudWatch metrics. In this section, you will view the metrics generated and setup an CloudWatch alarm to be triggered when the model quality drifts from the baseline thresholds. You could use CloudWatch alarms to trigger remedial actions such as retraining your model or updating the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 List the CW metrics generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CloudWatch client\n",
    "cw_client = boto3.Session().client(\"cloudwatch\")\n",
    "\n",
    "namespace = \"aws/sagemaker/Endpoints/model-metrics\"\n",
    "\n",
    "cw_dimensions = [\n",
    "    {\"Name\": \"Endpoint\", \"Value\": endpoint_name},\n",
    "    {\"Name\": \"MonitoringSchedule\", \"Value\": churn_monitor_schedule_name},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List metrics through the pagination interface\n",
    "paginator = cw_client.get_paginator(\"list_metrics\")\n",
    "\n",
    "for response in paginator.paginate(Dimensions=cw_dimensions, Namespace=namespace):\n",
    "    model_quality_metrics = response[\"Metrics\"]\n",
    "    for metric in model_quality_metrics:\n",
    "        print(metric[\"MetricName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Create a CloudWatch Alarm\n",
    "\n",
    "Based on the cloud watch metrics, you can create a cloud watch alarm when a specific metric does not meet the threshold configured. Here you will create an alarm if the f2 value of the model fall below the threshold suggested by the baseline constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarm_name = \"MODEL_QUALITY_F2_SCORE\"\n",
    "alarm_desc = (\n",
    "    \"Trigger an CloudWatch alarm when the f2 score drifts away from the baseline constraints\"\n",
    ")\n",
    "mdoel_quality_f2_drift_threshold = (\n",
    "    0.625  ##Setting this threshold purposefully low to see the alarm quickly.\n",
    ")\n",
    "metric_name = \"f2\"\n",
    "namespace = \"aws/sagemaker/Endpoints/model-metrics\"\n",
    "\n",
    "cw_client.put_metric_alarm(\n",
    "    AlarmName=alarm_name,\n",
    "    AlarmDescription=alarm_desc,\n",
    "    ActionsEnabled=True,\n",
    "    MetricName=metric_name,\n",
    "    Namespace=namespace,\n",
    "    Statistic=\"Average\",\n",
    "    Dimensions=[\n",
    "        {\"Name\": \"Endpoint\", \"Value\": endpoint_name},\n",
    "        {\"Name\": \"MonitoringSchedule\", \"Value\": churn_monitor_schedule_name},\n",
    "    ],\n",
    "    Period=600,\n",
    "    EvaluationPeriods=1,\n",
    "    DatapointsToAlarm=1,\n",
    "    Threshold=mdoel_quality_f2_drift_threshold,\n",
    "    ComparisonOperator=\"LessThanOrEqualToThreshold\",\n",
    "    TreatMissingData=\"breaching\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the CW Alarm is generated, you can decide on what actions you want to take on these alerts.  A possible action could be updating the training data an retraining the model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up <a id='cleanup'></a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can keep your endpoint running to continue capturing data. If you do not plan to collect more data or use this endpoint further, you should delete the endpoint to avoid incurring additional charges. Note that deleting your endpoint does not delete the data that was captured during the model invocations. That data persists in Amazon S3 until you delete it yourself.\n",
    "\n",
    "But before that, you need to delete the schedule first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_model_quality_monitor.delete_monitoring_schedule()\n",
    "sleep(60)  # actually wait for the deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bias_monitor.stop_monitoring_schedule()\n",
    "model_bias_monitor.delete_monitoring_schedule()\n",
    "sleep(60)  # actually wait for the deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
